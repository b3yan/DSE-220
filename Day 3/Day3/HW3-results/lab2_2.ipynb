{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "arctic-concern",
   "metadata": {},
   "source": [
    "## 2. Support vector machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "loose-slovakia",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt \n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "stuffed-lindsay",
   "metadata": {},
   "source": [
    "### (a) Is this data linearly separable?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dominican-contribution",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Yes')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hourly-referral",
   "metadata": {},
   "source": [
    "### (b) Use sklearn.svm.SVC to fit a support vector machine classifier to the data. You will need to invoke the option kernel=’linear’. Try at least 10 different values of the slack parameter C. In your writeup, include a table that shows these values of C and for each of them gives the training error and the number of support vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "transsexual-declaration",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets \n",
    "iris = datasets.load_iris() \n",
    "x = iris.data\n",
    "y = iris.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "centered-library",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_inputs_1 = x[:, [0, 2]]\n",
    "x_inputs = x_inputs_1[y!=0]\n",
    "y_labels = y[y!= 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "soviet-rogers",
   "metadata": {},
   "outputs": [],
   "source": [
    "C_list = [100, 10, 1, 0.1, 0.001, 0.000001, 0.000000001 ,0.000000000001 ,0.000000000000001 ,0.000000000000000001]\n",
    "error_list = []\n",
    "num = []\n",
    "for C in C_list:\n",
    "    #print('\\nC =', C)\n",
    "    svc = SVC(kernel='linear', C=C).fit(x_inputs, y_labels)\n",
    "    error = 1- svc.score(x_inputs, y_labels)\n",
    "    #print('training_error =', error)\n",
    "    error_list.append(error)\n",
    "    num.append(svc.n_support_)\n",
    "    #print('number_of_support_vectors =', svc.n_support_)\n",
    "\n",
    "total_list = pd.DataFrame({'C' : C_list,\n",
    "                            'Training Error' : error_list,\n",
    "                            'Number of support vectors' : num }, \n",
    "                                columns=['C','Training Error', 'Number of support vectors'])\n",
    "total_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "arbitrary-switch",
   "metadata": {},
   "source": [
    "### (c) Which value of C do you think is best? For this value, include a plot of the data points and the linear decision boundary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "worth-moral",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('C = 1 is the best')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "greek-theta",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = SVC(kernel='linear', C=1)\n",
    "clf.fit(x_inputs, y_labels)\n",
    "\n",
    "# Plot the data and the classification with the decision boundary.\n",
    "xmin, xmax = 4, 9\n",
    "ymin, ymax = 2, 8\n",
    "\n",
    "xd = np.array([xmin, xmax])\n",
    "\n",
    "weights1 = clf.coef_[0]\n",
    "bias1 = clf.intercept_[0]\n",
    "slope1 = - weights1[0]/weights1[1]\n",
    "x2cut1 = - bias1/weights1[1]\n",
    "yd1 = slope1*xd + x2cut1\n",
    "\n",
    "from matplotlib.pyplot import figure\n",
    "figure(figsize=(10, 10), dpi=80)\n",
    "\n",
    "plt.title('Decision boundary')\n",
    "plt.xlabel('X_1')\n",
    "plt.ylabel('X_2')\n",
    "\n",
    "plt.plot(xd, yd1, 'r', lw=2, ls='--')\n",
    "\n",
    "plt.scatter(*x_inputs[:,[0,1]][y_labels==1].T, s = 60, alpha = 0.9, marker = '*')\n",
    "plt.scatter(*x_inputs[:,[0,1]][y_labels==2].T, s = 60, alpha = 0.9, marker = '>')\n",
    "\n",
    "plt.xlim(xmin, xmax)\n",
    "plt.ylim(ymin, ymax)\n",
    "\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daily-output",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
