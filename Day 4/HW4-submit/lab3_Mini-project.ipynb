{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "accessory-holiday",
   "metadata": {},
   "source": [
    "# Lab 3_Mini-project"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "italian-editing",
   "metadata": {},
   "source": [
    "## The large number of English words can make language-based applications daunting. To cope with this, it is helpful to have a clustering or embedding of these words, so that words with similar meanings are clustered together, or have embeddings that are close to one another.\n",
    "## But how can we get at the meanings of words? John Firth (1957) put it thus:\n",
    "\n",
    "## You shall know a word by the company it keeps.\n",
    "\n",
    "## That is, words that tend to appear in similar contexts are likely to be related. In this assignment, you will investigate this idea by coming up with an embedding of words that is based on co-occurrence statistics.\n",
    "\n",
    "## The description here assumes you are using Python with NLTK."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "confused-electric",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.corpus import brown\n",
    "import re\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from nltk.tokenize import word_tokenize \n",
    "from collections import Counter\n",
    "import operator\n",
    "import collections\n",
    "import itertools\n",
    "#from gensim.models import Word2Vec\n",
    "from nltk.cluster import KMeansClusterer\n",
    "from sklearn import cluster\n",
    "from sklearn import metrics\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.manifold import TSNE\n",
    "from pylab import rcParams\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "advanced-fairy",
   "metadata": {},
   "source": [
    "## • First, download the Brown corpus (using nltk.corpus). This is a collection of text samples from a wide range of sources, with a total of over a million words. Calling brown.words() returns this text in one long list, which is useful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "senior-adoption",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package brown to /Users/boyan/nltk_data...\n",
      "[nltk_data]   Package brown is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('brown')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "moved-ethics",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The', 'Fulton', 'County', 'Grand', 'Jury', 'said', ...]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.corpus.brown.words()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "swedish-judgment",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The', 'Fulton', 'County', 'Grand', 'Jury', 'said', ...]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = []\n",
    "text = nltk.corpus.brown.words()\n",
    "text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "attached-pantyhose",
   "metadata": {},
   "source": [
    "## • Remove stopwords and punctuation, make everything lowercase, and count how often each word occurs. Use this to come up with two lists:\n",
    "    – A vocabulary V , consisting of a few thousand (e.g., 5000) of the most commonly-occurring words.\n",
    "    – A shorter list C of at most 1000 of the most commonly-occurring words, which we shall call context words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "military-highway",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Fulton</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>County</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Grand</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Jury</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>952520</th>\n",
       "      <td>the</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>952521</th>\n",
       "      <td>boucle</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>952522</th>\n",
       "      <td>dress</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>952523</th>\n",
       "      <td>was</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>952524</th>\n",
       "      <td>stupefying</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>952525 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              word\n",
       "0              The\n",
       "1           Fulton\n",
       "2           County\n",
       "3            Grand\n",
       "4             Jury\n",
       "...            ...\n",
       "952520         the\n",
       "952521      boucle\n",
       "952522       dress\n",
       "952523         was\n",
       "952524  stupefying\n",
       "\n",
       "[952525 rows x 1 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# remove punctuations and digits\n",
    "text_r = []\n",
    "for i in text:\n",
    "    text_r.append(re.sub(\"[^a-zA-Z]\", \" \", i))\n",
    "\n",
    "text_r_1 = list(filter(lambda x: x.isalpha() and len(x) > 1, text_r))\n",
    "    \n",
    "df_text = pd.DataFrame(text_r_1, columns=['word'])\n",
    "df_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "outer-extra",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>the</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>fulton</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>county</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>grand</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>jury</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>952520</th>\n",
       "      <td>the</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>952521</th>\n",
       "      <td>boucle</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>952522</th>\n",
       "      <td>dress</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>952523</th>\n",
       "      <td>was</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>952524</th>\n",
       "      <td>stupefying</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>952525 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              word\n",
       "0              the\n",
       "1           fulton\n",
       "2           county\n",
       "3            grand\n",
       "4             jury\n",
       "...            ...\n",
       "952520         the\n",
       "952521      boucle\n",
       "952522       dress\n",
       "952523         was\n",
       "952524  stupefying\n",
       "\n",
       "[952525 rows x 1 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert upper case to lower case\n",
    "text_r_l = []\n",
    "for i in range(df_text.word.shape[0]):\n",
    "    text_r_l.append(df_text.word[i].lower())\n",
    "text_r_l = pd.DataFrame(text_r_l, columns=['word'])\n",
    "text_r_l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "technological-virginia",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /Users/boyan/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "stopwords = []\n",
    "nltk.download(\"stopwords\")\n",
    "stopwords = nltk.corpus.stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "posted-landscape",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "508631"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_text = [w for w in text_r_l.word if not w in stopwords] \n",
    "len(filtered_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "intellectual-century",
   "metadata": {},
   "outputs": [],
   "source": [
    "# count how often each word occurs.\n",
    "word_count = dict(Counter(filtered_text))\n",
    "sorted_words = sorted(word_count.items(), key = operator.itemgetter(1), reverse = True)\n",
    "# first 5000 most commonly-occuring words\n",
    "V = [x[0] for x in sorted_words[:5000]]\n",
    "C = V[:1000]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "engaged-vietnam",
   "metadata": {},
   "source": [
    "## • For each word w ∈ V , and each occurrence of it in the text stream, look at the surrounding window of four words (two before, two after). Keep count of how often context words from C appear in these positions around word w. That is, for w ∈ V,c ∈ C, define\n",
    "\n",
    "## n(w, c) = # of times c occurs in a window around w.\n",
    "\n",
    "## Using these counts, construct the probability distribution Pr(c|w) of context words around w (for each w ∈ V ), as well as the overall distribution Pr(c) of context words. These are distributions over C."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "prospective-pathology",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>V_Word</th>\n",
       "      <th>C_Word</th>\n",
       "      <th>Cword_Count</th>\n",
       "      <th>Window_Count</th>\n",
       "      <th>Pr_cw</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>one</td>\n",
       "      <td>major</td>\n",
       "      <td>12</td>\n",
       "      <td>3292</td>\n",
       "      <td>0.003645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>one</td>\n",
       "      <td>wanted</td>\n",
       "      <td>8</td>\n",
       "      <td>3292</td>\n",
       "      <td>0.002430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>one</td>\n",
       "      <td>wait</td>\n",
       "      <td>1</td>\n",
       "      <td>3292</td>\n",
       "      <td>0.000304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>one</td>\n",
       "      <td>make</td>\n",
       "      <td>33</td>\n",
       "      <td>3292</td>\n",
       "      <td>0.010024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>one</td>\n",
       "      <td>first</td>\n",
       "      <td>38</td>\n",
       "      <td>3292</td>\n",
       "      <td>0.011543</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  V_Word  C_Word  Cword_Count  Window_Count     Pr_cw\n",
       "0    one   major           12          3292  0.003645\n",
       "1    one  wanted            8          3292  0.002430\n",
       "2    one    wait            1          3292  0.000304\n",
       "3    one    make           33          3292  0.010024\n",
       "4    one   first           38          3292  0.011543"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def ls_uniq(seq): \n",
    "   checked = []\n",
    "   for e in seq:\n",
    "       if e not in checked:\n",
    "           checked.append(e)\n",
    "   return checked\n",
    "\n",
    "c_words = []\n",
    "for v_word in V:\n",
    "    four_words = []\n",
    "    positions = [x for x, n in enumerate(filtered_text) if n == v_word] # locate each word of V in filter_words\n",
    "    \n",
    "    for i in positions:\n",
    "        if i ==0:\n",
    "            four_word = filtered_text[1:3]\n",
    "        elif i == 1:\n",
    "            four_word = ([filtered_text[0]] + filtered_text[2:4])\n",
    "        else:\n",
    "            four_word = (filtered_text[(i-2):i] + filtered_text[(i+1):(i+3)])\n",
    "        four_word_uniq = ls_uniq(four_word)\n",
    "        four_words = four_words + four_word_uniq\n",
    "        \n",
    "    four_words_count = dict(collections.Counter(four_words))\n",
    "    window_count = len(positions)\n",
    "    \n",
    "    for c_word in four_words_count:\n",
    "        if c_word in C:\n",
    "            cword_fre = four_words_count[c_word]\n",
    "            Pr_cw = cword_fre/window_count\n",
    "            c_words.append((v_word, c_word, cword_fre, window_count, Pr_cw))\n",
    "            \n",
    "cwords = pd.DataFrame(c_words)\n",
    "cwords.columns = ['V_Word','C_Word','Cword_Count','Window_Count','Pr_cw']\n",
    "cwords.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "adolescent-benjamin",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>V_Word</th>\n",
       "      <th>C_Word</th>\n",
       "      <th>Cword_Count</th>\n",
       "      <th>Window_Count</th>\n",
       "      <th>Pr_cw</th>\n",
       "      <th>Pr_c</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>one</td>\n",
       "      <td>major</td>\n",
       "      <td>12</td>\n",
       "      <td>3292</td>\n",
       "      <td>0.003645</td>\n",
       "      <td>0.000486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>one</td>\n",
       "      <td>wanted</td>\n",
       "      <td>8</td>\n",
       "      <td>3292</td>\n",
       "      <td>0.002430</td>\n",
       "      <td>0.000444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>one</td>\n",
       "      <td>wait</td>\n",
       "      <td>1</td>\n",
       "      <td>3292</td>\n",
       "      <td>0.000304</td>\n",
       "      <td>0.000185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>one</td>\n",
       "      <td>make</td>\n",
       "      <td>33</td>\n",
       "      <td>3292</td>\n",
       "      <td>0.010024</td>\n",
       "      <td>0.001561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>one</td>\n",
       "      <td>first</td>\n",
       "      <td>38</td>\n",
       "      <td>3292</td>\n",
       "      <td>0.011543</td>\n",
       "      <td>0.002676</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  V_Word  C_Word  Cword_Count  Window_Count     Pr_cw      Pr_c\n",
       "0    one   major           12          3292  0.003645  0.000486\n",
       "1    one  wanted            8          3292  0.002430  0.000444\n",
       "2    one    wait            1          3292  0.000304  0.000185\n",
       "3    one    make           33          3292  0.010024  0.001561\n",
       "4    one   first           38          3292  0.011543  0.002676"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cwords_uniq = list(cwords['C_Word'].unique())\n",
    "cwords_pro = {}\n",
    "for cword in cwords_uniq:\n",
    "    cwords_pro[cword] = filtered_text.count(cword) / len(filtered_text)\n",
    "def cword_pro(x):\n",
    "    return cwords_pro[x]\n",
    "cwords['Pr_c'] = cwords['C_Word'].apply(cword_pro)\n",
    "cwords.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "invalid-catholic",
   "metadata": {},
   "source": [
    "## • Represent each vocabulary item w by a |C|-dimensional vector Φ(w). This is known as the (positive) pointwise mutual information, and has been quite successful in work on word embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "printable-robert",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>V_Word</th>\n",
       "      <th>C_Word</th>\n",
       "      <th>Cword_Count</th>\n",
       "      <th>Window_Count</th>\n",
       "      <th>Pr_cw</th>\n",
       "      <th>Pr_c</th>\n",
       "      <th>f_w</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>one</td>\n",
       "      <td>major</td>\n",
       "      <td>12</td>\n",
       "      <td>3292</td>\n",
       "      <td>0.003645</td>\n",
       "      <td>0.000486</td>\n",
       "      <td>2.015746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>one</td>\n",
       "      <td>wanted</td>\n",
       "      <td>8</td>\n",
       "      <td>3292</td>\n",
       "      <td>0.002430</td>\n",
       "      <td>0.000444</td>\n",
       "      <td>1.699134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>one</td>\n",
       "      <td>wait</td>\n",
       "      <td>1</td>\n",
       "      <td>3292</td>\n",
       "      <td>0.000304</td>\n",
       "      <td>0.000185</td>\n",
       "      <td>0.496933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>one</td>\n",
       "      <td>make</td>\n",
       "      <td>33</td>\n",
       "      <td>3292</td>\n",
       "      <td>0.010024</td>\n",
       "      <td>0.001561</td>\n",
       "      <td>1.859652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>one</td>\n",
       "      <td>first</td>\n",
       "      <td>38</td>\n",
       "      <td>3292</td>\n",
       "      <td>0.011543</td>\n",
       "      <td>0.002676</td>\n",
       "      <td>1.461839</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  V_Word  C_Word  Cword_Count  Window_Count     Pr_cw      Pr_c       f_w\n",
       "0    one   major           12          3292  0.003645  0.000486  2.015746\n",
       "1    one  wanted            8          3292  0.002430  0.000444  1.699134\n",
       "2    one    wait            1          3292  0.000304  0.000185  0.496933\n",
       "3    one    make           33          3292  0.010024  0.001561  1.859652\n",
       "4    one   first           38          3292  0.011543  0.002676  1.461839"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def max_log(row):\n",
    "    f = row['Pr_cw']\n",
    "    g = row['Pr_c']\n",
    "    l = np.math.log(f/g)\n",
    "    return max(0, l)\n",
    "cwords['f_w'] = cwords.apply(max_log, axis = 1)\n",
    "cwords.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "respiratory-reconstruction",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>C_Word</th>\n",
       "      <th>able</th>\n",
       "      <th>accepted</th>\n",
       "      <th>according</th>\n",
       "      <th>account</th>\n",
       "      <th>across</th>\n",
       "      <th>act</th>\n",
       "      <th>action</th>\n",
       "      <th>activities</th>\n",
       "      <th>activity</th>\n",
       "      <th>actual</th>\n",
       "      <th>...</th>\n",
       "      <th>writing</th>\n",
       "      <th>written</th>\n",
       "      <th>wrong</th>\n",
       "      <th>wrote</th>\n",
       "      <th>year</th>\n",
       "      <th>years</th>\n",
       "      <th>yes</th>\n",
       "      <th>yet</th>\n",
       "      <th>york</th>\n",
       "      <th>young</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V_Word</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>abandoned</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.275155</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>abel</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ability</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.797542</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>able</th>\n",
       "      <td>3.082068</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.002026</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.118753</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.010609</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>3.002026</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.810956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aboard</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.278695</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1000 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "C_Word         able  accepted  according   account    across       act  \\\n",
       "V_Word                                                                   \n",
       "abandoned       NaN       NaN        NaN       NaN       NaN  4.275155   \n",
       "abel            NaN       NaN        NaN       NaN       NaN       NaN   \n",
       "ability         NaN       NaN        NaN       NaN       NaN       NaN   \n",
       "able       3.082068       NaN        NaN  3.002026       NaN  2.118753   \n",
       "aboard          NaN       NaN        NaN       NaN  4.278695       NaN   \n",
       "\n",
       "C_Word     action  activities  activity  actual  ...   writing  written  \\\n",
       "V_Word                                           ...                      \n",
       "abandoned     NaN         NaN       NaN     NaN  ...       NaN      NaN   \n",
       "abel          NaN         NaN       NaN     NaN  ...       NaN      NaN   \n",
       "ability       NaN         NaN       NaN     NaN  ...       NaN      NaN   \n",
       "able          NaN         NaN  3.010609     NaN  ...  3.002026      NaN   \n",
       "aboard        NaN         NaN       NaN     NaN  ...       NaN      NaN   \n",
       "\n",
       "C_Word     wrong  wrote  year  years  yes       yet  york     young  \n",
       "V_Word                                                               \n",
       "abandoned    NaN    NaN   NaN    NaN  NaN       NaN   NaN       NaN  \n",
       "abel         NaN    NaN   NaN    NaN  NaN       NaN   NaN       NaN  \n",
       "ability      NaN    NaN   NaN    NaN  NaN  2.797542   NaN       NaN  \n",
       "able         NaN    NaN   NaN    NaN  NaN       NaN   NaN  1.810956  \n",
       "aboard       NaN    NaN   NaN    NaN  NaN       NaN   NaN       NaN  \n",
       "\n",
       "[5 rows x 1000 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mutal_words = pd.pivot_table(cwords, index = 'V_Word', columns = 'C_Word', values = 'f_w')\n",
    "mutal_words.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "veterinary-socket",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>C_Word</th>\n",
       "      <th>able</th>\n",
       "      <th>accepted</th>\n",
       "      <th>according</th>\n",
       "      <th>account</th>\n",
       "      <th>across</th>\n",
       "      <th>act</th>\n",
       "      <th>action</th>\n",
       "      <th>activities</th>\n",
       "      <th>activity</th>\n",
       "      <th>actual</th>\n",
       "      <th>...</th>\n",
       "      <th>writing</th>\n",
       "      <th>written</th>\n",
       "      <th>wrong</th>\n",
       "      <th>wrote</th>\n",
       "      <th>year</th>\n",
       "      <th>years</th>\n",
       "      <th>yes</th>\n",
       "      <th>yet</th>\n",
       "      <th>york</th>\n",
       "      <th>young</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V_Word</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>abandoned</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.275155</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>abel</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ability</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.797542</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>able</th>\n",
       "      <td>3.082068</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.002026</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.118753</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.010609</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3.002026</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.810956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aboard</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.278695</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1000 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "C_Word         able  accepted  according   account    across       act  \\\n",
       "V_Word                                                                   \n",
       "abandoned  0.000000       0.0        0.0  0.000000  0.000000  4.275155   \n",
       "abel       0.000000       0.0        0.0  0.000000  0.000000  0.000000   \n",
       "ability    0.000000       0.0        0.0  0.000000  0.000000  0.000000   \n",
       "able       3.082068       0.0        0.0  3.002026  0.000000  2.118753   \n",
       "aboard     0.000000       0.0        0.0  0.000000  4.278695  0.000000   \n",
       "\n",
       "C_Word     action  activities  activity  actual  ...   writing  written  \\\n",
       "V_Word                                           ...                      \n",
       "abandoned     0.0         0.0  0.000000     0.0  ...  0.000000      0.0   \n",
       "abel          0.0         0.0  0.000000     0.0  ...  0.000000      0.0   \n",
       "ability       0.0         0.0  0.000000     0.0  ...  0.000000      0.0   \n",
       "able          0.0         0.0  3.010609     0.0  ...  3.002026      0.0   \n",
       "aboard        0.0         0.0  0.000000     0.0  ...  0.000000      0.0   \n",
       "\n",
       "C_Word     wrong  wrote  year  years  yes       yet  york     young  \n",
       "V_Word                                                               \n",
       "abandoned    0.0    0.0   0.0    0.0  0.0  0.000000   0.0  0.000000  \n",
       "abel         0.0    0.0   0.0    0.0  0.0  0.000000   0.0  0.000000  \n",
       "ability      0.0    0.0   0.0    0.0  0.0  2.797542   0.0  0.000000  \n",
       "able         0.0    0.0   0.0    0.0  0.0  0.000000   0.0  1.810956  \n",
       "aboard       0.0    0.0   0.0    0.0  0.0  0.000000   0.0  0.000000  \n",
       "\n",
       "[5 rows x 1000 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mutal_words = mutal_words.fillna(0)\n",
    "mutal_words.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "beneficial-scottish",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>90</th>\n",
       "      <th>91</th>\n",
       "      <th>92</th>\n",
       "      <th>93</th>\n",
       "      <th>94</th>\n",
       "      <th>95</th>\n",
       "      <th>96</th>\n",
       "      <th>97</th>\n",
       "      <th>98</th>\n",
       "      <th>99</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V_Word</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>abandoned</th>\n",
       "      <td>5.960956</td>\n",
       "      <td>-0.799199</td>\n",
       "      <td>-0.443532</td>\n",
       "      <td>0.477622</td>\n",
       "      <td>0.188357</td>\n",
       "      <td>-0.007875</td>\n",
       "      <td>-1.262637</td>\n",
       "      <td>-0.626547</td>\n",
       "      <td>-0.214247</td>\n",
       "      <td>0.904428</td>\n",
       "      <td>...</td>\n",
       "      <td>1.989921</td>\n",
       "      <td>-1.180750</td>\n",
       "      <td>-0.341614</td>\n",
       "      <td>-0.226722</td>\n",
       "      <td>-0.521254</td>\n",
       "      <td>-0.318842</td>\n",
       "      <td>-0.175451</td>\n",
       "      <td>0.712065</td>\n",
       "      <td>0.108735</td>\n",
       "      <td>0.817915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>abel</th>\n",
       "      <td>5.741608</td>\n",
       "      <td>5.306603</td>\n",
       "      <td>1.364197</td>\n",
       "      <td>0.465327</td>\n",
       "      <td>0.085904</td>\n",
       "      <td>-0.433129</td>\n",
       "      <td>-1.344058</td>\n",
       "      <td>1.126805</td>\n",
       "      <td>-1.375314</td>\n",
       "      <td>0.283099</td>\n",
       "      <td>...</td>\n",
       "      <td>1.071310</td>\n",
       "      <td>2.634924</td>\n",
       "      <td>1.321961</td>\n",
       "      <td>0.471964</td>\n",
       "      <td>0.701810</td>\n",
       "      <td>0.080597</td>\n",
       "      <td>-0.825543</td>\n",
       "      <td>-0.675054</td>\n",
       "      <td>0.076028</td>\n",
       "      <td>-0.354717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ability</th>\n",
       "      <td>13.572285</td>\n",
       "      <td>-3.672069</td>\n",
       "      <td>-6.581054</td>\n",
       "      <td>1.495166</td>\n",
       "      <td>0.523935</td>\n",
       "      <td>-1.316302</td>\n",
       "      <td>0.390778</td>\n",
       "      <td>-2.596461</td>\n",
       "      <td>-0.739812</td>\n",
       "      <td>-0.951102</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.415406</td>\n",
       "      <td>-2.488828</td>\n",
       "      <td>3.593068</td>\n",
       "      <td>0.030965</td>\n",
       "      <td>1.542010</td>\n",
       "      <td>0.864126</td>\n",
       "      <td>-1.477301</td>\n",
       "      <td>-1.565202</td>\n",
       "      <td>-2.383625</td>\n",
       "      <td>-1.370630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>able</th>\n",
       "      <td>22.168586</td>\n",
       "      <td>-0.288742</td>\n",
       "      <td>-4.411252</td>\n",
       "      <td>-0.904856</td>\n",
       "      <td>2.287316</td>\n",
       "      <td>-2.656532</td>\n",
       "      <td>2.975976</td>\n",
       "      <td>-2.467121</td>\n",
       "      <td>-1.153804</td>\n",
       "      <td>-1.618188</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.099205</td>\n",
       "      <td>0.701866</td>\n",
       "      <td>0.185872</td>\n",
       "      <td>0.171973</td>\n",
       "      <td>1.363279</td>\n",
       "      <td>0.486987</td>\n",
       "      <td>-0.129082</td>\n",
       "      <td>0.754172</td>\n",
       "      <td>-2.233285</td>\n",
       "      <td>0.731055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aboard</th>\n",
       "      <td>6.606274</td>\n",
       "      <td>3.376979</td>\n",
       "      <td>1.393158</td>\n",
       "      <td>-0.672356</td>\n",
       "      <td>-0.731437</td>\n",
       "      <td>0.684725</td>\n",
       "      <td>-1.115608</td>\n",
       "      <td>0.326978</td>\n",
       "      <td>-0.562371</td>\n",
       "      <td>-0.128536</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.838595</td>\n",
       "      <td>1.685687</td>\n",
       "      <td>-2.063308</td>\n",
       "      <td>-0.119458</td>\n",
       "      <td>1.229330</td>\n",
       "      <td>0.077308</td>\n",
       "      <td>-1.512016</td>\n",
       "      <td>-1.404849</td>\n",
       "      <td>1.308275</td>\n",
       "      <td>1.978615</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 100 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  0         1         2         3         4         5   \\\n",
       "V_Word                                                                   \n",
       "abandoned   5.960956 -0.799199 -0.443532  0.477622  0.188357 -0.007875   \n",
       "abel        5.741608  5.306603  1.364197  0.465327  0.085904 -0.433129   \n",
       "ability    13.572285 -3.672069 -6.581054  1.495166  0.523935 -1.316302   \n",
       "able       22.168586 -0.288742 -4.411252 -0.904856  2.287316 -2.656532   \n",
       "aboard      6.606274  3.376979  1.393158 -0.672356 -0.731437  0.684725   \n",
       "\n",
       "                 6         7         8         9   ...        90        91  \\\n",
       "V_Word                                             ...                       \n",
       "abandoned -1.262637 -0.626547 -0.214247  0.904428  ...  1.989921 -1.180750   \n",
       "abel      -1.344058  1.126805 -1.375314  0.283099  ...  1.071310  2.634924   \n",
       "ability    0.390778 -2.596461 -0.739812 -0.951102  ... -0.415406 -2.488828   \n",
       "able       2.975976 -2.467121 -1.153804 -1.618188  ... -0.099205  0.701866   \n",
       "aboard    -1.115608  0.326978 -0.562371 -0.128536  ... -0.838595  1.685687   \n",
       "\n",
       "                 92        93        94        95        96        97  \\\n",
       "V_Word                                                                  \n",
       "abandoned -0.341614 -0.226722 -0.521254 -0.318842 -0.175451  0.712065   \n",
       "abel       1.321961  0.471964  0.701810  0.080597 -0.825543 -0.675054   \n",
       "ability    3.593068  0.030965  1.542010  0.864126 -1.477301 -1.565202   \n",
       "able       0.185872  0.171973  1.363279  0.486987 -0.129082  0.754172   \n",
       "aboard    -2.063308 -0.119458  1.229330  0.077308 -1.512016 -1.404849   \n",
       "\n",
       "                 98        99  \n",
       "V_Word                         \n",
       "abandoned  0.108735  0.817915  \n",
       "abel       0.076028 -0.354717  \n",
       "ability   -2.383625 -1.370630  \n",
       "able      -2.233285  0.731055  \n",
       "aboard     1.308275  1.978615  \n",
       "\n",
       "[5 rows x 100 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.random_projection import sparse_random_matrix\n",
    "X = np.asarray(mutal_words)\n",
    "svd = TruncatedSVD(n_components = 100, n_iter = 7, random_state = 42)\n",
    "svd.fit(X)\n",
    "X_reduce = svd.fit_transform(X)\n",
    "X_reduce_df = pd.DataFrame(X_reduce, index = mutal_words.index)\n",
    "X_reduce_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "hearing-throat",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>V_Word</th>\n",
       "      <th>abandoned</th>\n",
       "      <th>abel</th>\n",
       "      <th>ability</th>\n",
       "      <th>able</th>\n",
       "      <th>aboard</th>\n",
       "      <th>abroad</th>\n",
       "      <th>abrupt</th>\n",
       "      <th>absence</th>\n",
       "      <th>absent</th>\n",
       "      <th>absolute</th>\n",
       "      <th>...</th>\n",
       "      <th>yesterday</th>\n",
       "      <th>yet</th>\n",
       "      <th>yield</th>\n",
       "      <th>york</th>\n",
       "      <th>young</th>\n",
       "      <th>younger</th>\n",
       "      <th>youngsters</th>\n",
       "      <th>youth</th>\n",
       "      <th>zen</th>\n",
       "      <th>zero</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V_Word</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>abandoned</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.968543</td>\n",
       "      <td>0.730406</td>\n",
       "      <td>0.533748</td>\n",
       "      <td>0.774131</td>\n",
       "      <td>0.693942</td>\n",
       "      <td>0.911359</td>\n",
       "      <td>0.725871</td>\n",
       "      <td>0.707896</td>\n",
       "      <td>0.616484</td>\n",
       "      <td>...</td>\n",
       "      <td>0.787070</td>\n",
       "      <td>0.586790</td>\n",
       "      <td>0.700104</td>\n",
       "      <td>0.598163</td>\n",
       "      <td>0.675748</td>\n",
       "      <td>0.737834</td>\n",
       "      <td>0.755079</td>\n",
       "      <td>0.592237</td>\n",
       "      <td>0.636707</td>\n",
       "      <td>0.721480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>abel</th>\n",
       "      <td>0.968543</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.860558</td>\n",
       "      <td>0.759046</td>\n",
       "      <td>0.618207</td>\n",
       "      <td>0.790844</td>\n",
       "      <td>0.780160</td>\n",
       "      <td>0.872887</td>\n",
       "      <td>0.805503</td>\n",
       "      <td>0.957827</td>\n",
       "      <td>...</td>\n",
       "      <td>0.661220</td>\n",
       "      <td>0.574107</td>\n",
       "      <td>0.827330</td>\n",
       "      <td>0.696694</td>\n",
       "      <td>0.576709</td>\n",
       "      <td>0.685788</td>\n",
       "      <td>0.897992</td>\n",
       "      <td>0.634144</td>\n",
       "      <td>0.966296</td>\n",
       "      <td>0.714998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ability</th>\n",
       "      <td>0.730406</td>\n",
       "      <td>0.860558</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.464315</td>\n",
       "      <td>0.869166</td>\n",
       "      <td>0.626037</td>\n",
       "      <td>0.544747</td>\n",
       "      <td>0.615985</td>\n",
       "      <td>0.636967</td>\n",
       "      <td>0.680457</td>\n",
       "      <td>...</td>\n",
       "      <td>0.738057</td>\n",
       "      <td>0.422524</td>\n",
       "      <td>0.800745</td>\n",
       "      <td>0.626822</td>\n",
       "      <td>0.512390</td>\n",
       "      <td>0.704118</td>\n",
       "      <td>0.609772</td>\n",
       "      <td>0.531239</td>\n",
       "      <td>0.713440</td>\n",
       "      <td>0.819370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>able</th>\n",
       "      <td>0.533748</td>\n",
       "      <td>0.759046</td>\n",
       "      <td>0.464315</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.603940</td>\n",
       "      <td>0.513003</td>\n",
       "      <td>0.571522</td>\n",
       "      <td>0.521385</td>\n",
       "      <td>0.553321</td>\n",
       "      <td>0.596704</td>\n",
       "      <td>...</td>\n",
       "      <td>0.676388</td>\n",
       "      <td>0.232921</td>\n",
       "      <td>0.611515</td>\n",
       "      <td>0.443027</td>\n",
       "      <td>0.389125</td>\n",
       "      <td>0.505643</td>\n",
       "      <td>0.553687</td>\n",
       "      <td>0.466592</td>\n",
       "      <td>0.598713</td>\n",
       "      <td>0.753794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aboard</th>\n",
       "      <td>0.774131</td>\n",
       "      <td>0.618207</td>\n",
       "      <td>0.869166</td>\n",
       "      <td>0.603940</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.682407</td>\n",
       "      <td>0.842458</td>\n",
       "      <td>0.742596</td>\n",
       "      <td>0.767136</td>\n",
       "      <td>0.803501</td>\n",
       "      <td>...</td>\n",
       "      <td>0.691455</td>\n",
       "      <td>0.576299</td>\n",
       "      <td>0.867090</td>\n",
       "      <td>0.593383</td>\n",
       "      <td>0.490432</td>\n",
       "      <td>0.549534</td>\n",
       "      <td>0.835697</td>\n",
       "      <td>0.614968</td>\n",
       "      <td>0.862326</td>\n",
       "      <td>0.794227</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 5000 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "V_Word     abandoned      abel   ability      able    aboard    abroad  \\\n",
       "V_Word                                                                   \n",
       "abandoned   1.000000  0.968543  0.730406  0.533748  0.774131  0.693942   \n",
       "abel        0.968543  1.000000  0.860558  0.759046  0.618207  0.790844   \n",
       "ability     0.730406  0.860558  1.000000  0.464315  0.869166  0.626037   \n",
       "able        0.533748  0.759046  0.464315  1.000000  0.603940  0.513003   \n",
       "aboard      0.774131  0.618207  0.869166  0.603940  1.000000  0.682407   \n",
       "\n",
       "V_Word       abrupt   absence    absent  absolute  ...  yesterday       yet  \\\n",
       "V_Word                                             ...                        \n",
       "abandoned  0.911359  0.725871  0.707896  0.616484  ...   0.787070  0.586790   \n",
       "abel       0.780160  0.872887  0.805503  0.957827  ...   0.661220  0.574107   \n",
       "ability    0.544747  0.615985  0.636967  0.680457  ...   0.738057  0.422524   \n",
       "able       0.571522  0.521385  0.553321  0.596704  ...   0.676388  0.232921   \n",
       "aboard     0.842458  0.742596  0.767136  0.803501  ...   0.691455  0.576299   \n",
       "\n",
       "V_Word        yield      york     young   younger  youngsters     youth  \\\n",
       "V_Word                                                                    \n",
       "abandoned  0.700104  0.598163  0.675748  0.737834    0.755079  0.592237   \n",
       "abel       0.827330  0.696694  0.576709  0.685788    0.897992  0.634144   \n",
       "ability    0.800745  0.626822  0.512390  0.704118    0.609772  0.531239   \n",
       "able       0.611515  0.443027  0.389125  0.505643    0.553687  0.466592   \n",
       "aboard     0.867090  0.593383  0.490432  0.549534    0.835697  0.614968   \n",
       "\n",
       "V_Word          zen      zero  \n",
       "V_Word                         \n",
       "abandoned  0.636707  0.721480  \n",
       "abel       0.966296  0.714998  \n",
       "ability    0.713440  0.819370  \n",
       "able       0.598713  0.753794  \n",
       "aboard     0.862326  0.794227  \n",
       "\n",
       "[5 rows x 5000 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity as cs\n",
    "words_similarity = 1 - cs(X_reduce, X_reduce)\n",
    "words_similarity_df = pd.DataFrame(words_similarity, index = \n",
    "mutal_words.index,columns = mutal_words.index)\n",
    "np.fill_diagonal(words_similarity_df.values, 1)\n",
    "words_similarity_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sought-gross",
   "metadata": {},
   "source": [
    "## (b) Nearest neighbor results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "periodic-karaoke",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "communism ------> century\n",
      "autumn ------> summer\n",
      "cigarette ------> wet\n",
      "pulmonary ------> artery\n",
      "mankind ------> world\n",
      "africa ------> asia\n",
      "chicago ------> portland\n",
      "revolution ------> world\n",
      "september ------> december\n",
      "chemical ------> feed\n",
      "detergent ------> fabrics\n",
      "dictionary ------> text\n",
      "storm ------> weekend\n",
      "worship ------> community\n"
     ]
    }
   ],
   "source": [
    "# according to similarity matrix to find the cloest meaning word\n",
    "words_list = ['communism', 'autumn', 'cigarette', 'pulmonary', 'mankind', 'africa', 'chicago', 'revolution', 'september', 'chemical', 'detergent', 'dictionary', 'storm', 'worship']\n",
    "words_similarity_dict = {}\n",
    "for word_list in words_list:\n",
    "    words_similarity_dict[word_list] = words_similarity_df[word_list].idxmin()\n",
    "for word_dict in words_similarity_dict:\n",
    "    print ('{} ------> {}'.format(word_dict, words_similarity_dict[word_dict]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "revised-symbol",
   "metadata": {},
   "source": [
    "### Yes, the results make sense!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "likely-bennett",
   "metadata": {},
   "source": [
    "## (c) Clustering.\n",
    "Using the vectorial representation Ψ(·), cluster the words in V into 100 groups. Clearly specify what algorithm and distance function you using for this, and the reasons for your choices.\n",
    "Look over the resulting 100 clusters. Do any of them seem even moderately coherent? Pick out a few of the best clusters and list the words in them."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "common-height",
   "metadata": {},
   "source": [
    "## Algorithm: KMeansCluster\n",
    "## Distance function: nltk.cluster.util.cosine_distance\n",
    "## Reasons: KMeans works iteractively, where initially each centroid is placed randomly in the vector space of the dataset and move themselves to the center of the points which are closer to them. In each new iteration the distance between each centroid and the points are recalculated and the centroids move again to the center of the closest points. The algorithm is finished when the position or the groups don’t change anymore or when the distance in which the centroids change doesn’t surpass a pre-defined threshold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dried-cement",
   "metadata": {},
   "outputs": [],
   "source": [
    "kclusterer = KMeansClusterer(100, distance=nltk.cluster.util.cosine_distance, repeats=25)\n",
    "assigned_clusters = kclusterer.cluster(X_reduce, assign_clusters=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "selected-sentence",
   "metadata": {},
   "source": [
    "## Yes, some of them seem even moderately coherent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "spiritual-closer",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pick out a few of the best clusters and list the words in them.\n",
    "strings = []\n",
    "for index, i in enumerate(X_reduce):    \n",
    "    strings.append(str(assigned_clusters[index]) + \":\" + X_reduce_df.index[assigned_clusters[index]])\n",
    "\n",
    "print(strings[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fallen-event",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
