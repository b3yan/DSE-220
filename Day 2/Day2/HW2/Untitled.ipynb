{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "champion-malta",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "import random\n",
    "\n",
    "# Constants\n",
    "BIAS = 1                            # Dummy Feature for use in setting constant factor in Training.\n",
    "TRAIN_TEST_RATIO = .75              # Default Ratio of data to be used in Training vs. Testing.\n",
    "ITERATIONS = 100                    # Default Number of Training Iterations.\n",
    "OUTPUT_PATH = \"classifier_models/\"  # Directory in which to save completed models.\n",
    "\n",
    "class MultiClassPerceptron():\n",
    "    # Analytics values\n",
    "    precision, recall, accuracy, fbeta_score = {}, {}, 0, {}\n",
    "    def __init__(self, classes, feature_list, feature_data, train_test_ratio=TRAIN_TEST_RATIO, iterations=ITERATIONS):\n",
    "        self.classes = classes\n",
    "        self.feature_list = feature_list\n",
    "        self.feature_data = feature_data\n",
    "        self.ratio = train_test_ratio\n",
    "        self.iterations = iterations\n",
    "\n",
    "        # Split feature data into train set, and test set\n",
    "        random.shuffle(self.feature_data)\n",
    "        self.train_set = self.feature_data[:int(len(self.feature_data) * self.ratio)]\n",
    "        self.test_set = self.feature_data[int(len(self.feature_data) * self.ratio):]\n",
    "\n",
    "        # Initialize empty weight vectors, with extra BIAS term.\n",
    "        self.weight_vectors = {c: np.array([0 for _ in xrange(len(feature_list) + 1)]) for c in self.classes}\n",
    "\n",
    "    def train(self):\n",
    "        for _ in xrange(self.iterations):\n",
    "            for category, feature_dict in self.train_set:\n",
    "                # Format feature values as a vector, with extra BIAS term.\n",
    "                feature_list = [feature_dict[k] for k in self.feature_list]\n",
    "                feature_list.append(BIAS)\n",
    "                feature_vector = np.array(feature_list)\n",
    "\n",
    "                # Initialize arg_max value, predicted class.\n",
    "                arg_max, predicted_class = 0, self.classes[0]\n",
    "\n",
    "                # Multi-Class Decision Rule:\n",
    "                for c in self.classes:\n",
    "                    current_activation = np.dot(feature_vector, self.weight_vectors[c])\n",
    "                    if current_activation >= arg_max:\n",
    "                        arg_max, predicted_class = current_activation, c\n",
    "\n",
    "                # Update Rule:\n",
    "                if not (category == predicted_class):\n",
    "                    self.weight_vectors[category] += feature_vector\n",
    "                    self.weight_vectors[predicted_class] -= feature_vector\n",
    "\n",
    "    def predict(self, feature_dict):\n",
    "        feature_list = [feature_dict[k] for k in self.feature_list]\n",
    "        feature_list.append(BIAS)\n",
    "        feature_vector = np.array(feature_list)\n",
    "\n",
    "        # Initialize arg_max value, predicted class.\n",
    "        arg_max, predicted_class = 0, self.classes[0]\n",
    "\n",
    "        # Multi-Class Decision Rule:\n",
    "        for c in self.classes:\n",
    "            current_activation = np.dot(feature_vector, self.weight_vectors[c])\n",
    "            if current_activation >= arg_max:\n",
    "                arg_max, predicted_class = current_activation, c\n",
    "\n",
    "        return predicted_class\n",
    "\n",
    "    def save_classifier(self, classifier_name):\n",
    "        with open(OUTPUT_PATH + classifier_name + \".pik\", 'wb') as f:\n",
    "            pickle.dump(self, f, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "    @staticmethod\n",
    "    def load_classifier(classifier_name):\n",
    "        with open(OUTPUT_PATH + classifier_name + \".pik\", 'rb') as f:\n",
    "            return pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "controlled-butterfly",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "japanese-martin",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = read_csv('data0.txt', header = None, sep = ' ')\n",
    "data.columns = [\"col1\", \"col2\", \"col3\", \"col4\"]\n",
    "data0 = data.drop(columns=[\"col4\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "purple-merchant",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "looking-faculty",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'shape_classes' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-6db9c46ddd85>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Simple Sandbox Script to demonstrate entire Pipeline (Loading, Training, Saving, getting Analytics)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mshape_classifier\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMultiClassPerceptron\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape_classes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape_feature_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape_feature_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mshape_classifier\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mshape_classifier\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_classifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"shape_classifier\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'shape_classes' is not defined"
     ]
    }
   ],
   "source": [
    "# Simple Sandbox Script to demonstrate entire Pipeline (Loading, Training, Saving, getting Analytics)\n",
    "if __name__ == \"__main__\":\n",
    "    shape_classifier = MultiClassPerceptron(shape_classes, shape_feature_list, shape_feature_data)\n",
    "    shape_classifier.train()\n",
    "    shape_classifier.save_classifier(\"shape_classifier\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "internal-extension",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
